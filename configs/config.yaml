k_surface: 32
surface_method: PCA
t1:
  decay:
    mode: exp_floor
    rate: 0.6
    floor: 0.05
  edge_type_mult: {supports: 1.0, associates: 0.6, contradicts: 0.8}
  iter_cap: 50
  node_budget: 1.5
  queue_budget: 10000
  radius_cap: 4
  cache:
    enabled: true
    max_entries: 512
    ttl_s: 300
t2:
  backend: inmemory
  k_retrieval: 64
  sim_threshold: 0.3
  tiers: [exact_semantic, cluster_semantic, archive]
  exact_recent_days: 30
  ranking: {alpha_sim: 0.75, beta_recency: 0.2, gamma_importance: 0.05}
  clusters_top_m: 3
  owner_scope: any
  residual_cap_per_turn: 32
  cache:
    enabled: true
    max_entries: 512
    ttl_s: 300
  lancedb:
    uri: ./.data/lancedb
    table: episodes
    meta_table: meta
    index:
      metric: cosine
      ef_search: 64
      m: 16
  # M7 quality controls (PR36 shadow scaffold; defaults OFF)
  quality:
    enabled: false
    shadow: false
    trace_dir: "logs/quality"
    redact: true
t3:
  apply_ops: false
  max_rag_loops: 1
  tokens: 256
  temp: 0.7
  max_ops_per_turn: 3
  allow_reflection: true
  backend: rulebased
  reflection:
    backend: rulebased        # deterministic summariser; "llm" requires fixtures (see PR84)
    summary_tokens: 128       # whitespace-tokenised cap
    embed: true               # embed the reflection summary deterministically
    log: true                 # write t3_reflection.jsonl (not part of identity logs)
    topk_snippets: 3          # number of retrieval snippets to include
  dialogue:
    template: "{style_prefix}| summary: {labels}. next: {intent}"
    include_top_k_snippets: 2
  policy:
    tau_high: 0.8
    tau_low: 0.4
    epsilon_edit: 0.10
  llm:
    # M3-07 LLM adapter scaffolding — defaults OFF and fixture-driven in CI
    provider: fixture           # "fixture" | "ollama"
    model: qwen3:4b-instruct-q4_K_M
    endpoint: http://localhost:11434/api/generate
    max_tokens: 256
    temp: 0.2
    timeout_ms: 10000
    fixtures:
      enabled: false            # fixtures-only mode for deterministic LLM reflection
      path: null                # set to fixture file path when enabled
t4:
  enabled: true
  delta_norm_cap_l2: 1.5
  novelty_cap_per_node: 0.3
  churn_cap_edges: 64
  cooldowns:
    EditGraph: 2
    CreateGraph: 10
  weight_min: -1.0
  weight_max: 1.0
  snapshot_every_n_turns: 1
  snapshot_dir: ./.data/snapshots
  cache_bust_mode: on-apply
  cache:
    enabled: true
    namespaces: []
    max_entries: 512
    ttl_sec: 600
# budgets: ...
budgets: {time_ms: 1000, ops: 1000, tokens: 1024, time_ms_reflection: 6000}
flags: {enable_world_memory: true, allow_reflection: true}

# -----------------------------------------------------------------------------
# M9 Deterministic Parallelism (defaults OFF)
# -----------------------------------------------------------------------------
perf:
  parallel:
    enabled: false
    max_workers: 0  # 0 or 1 = sequential
    t1: false
    t2: false
    agents: false

# -----------------------------------------------------------------------------
# Scheduler (M5) — Example config (feature-flagged; defaults live in validate.py)
# -----------------------------------------------------------------------------
# scheduler:
#   enabled: false
#   policy: round_robin   # or fair_queue
#   quantum_ms: 20
#   budgets:
#     t1_pops: null       # int or null
#     t1_iters: 50
#     t2_k: 64            # cap on results USED (not fetched)
#     t3_ops: 3
#     time_ms_reflection: 6000  # reflection time budget
#     ops_reflection: 5         # max reflection memory writes per turn
#     wall_ms: 200        # must be >= quantum_ms
#   fairness:
#     max_consecutive_turns: 1  # enforced in PR27
#     aging_ms: 200              # bucket size for fair-queue priority

# -----------------------------------------------------------------------------
# M6 Performance & Compaction (defaults OFF) — Commented example only
# -----------------------------------------------------------------------------
# perf:
#   enabled: false
#   t1:
#     queue_cap: 10000            # frontier/visited max sizes (deterministic evict)
#     dedupe_window: 8192         # ring buffer for recent-node dedupe
#     cache:
#       max_entries: 512
#       max_bytes: 64000000       # soft cap; LRU beyond this
#   t2:
#     embed_dtype: "fp32"          # compute dtype (math)
#     embed_store_dtype: "fp32"    # storage dtype; PR33 may set "fp16"
#     precompute_norms: true       # keep fp32 norms when store is fp16
#     cache:
#       max_entries: 512
#       max_bytes: 128000000
#   snapshots:
#     compression: "zstd"          # "none" | "zstd"
#     level: 3
#     delta_mode: false            # if true, writer may emit delta snapshots
#     every_n_turns: 1
#   metrics:
#     report_memory: true          # gated emission of memory counters

# -----------------------------------------------------------------------------
# M7 Retrieval Quality — Prep only (no runtime wiring in M6)
# -----------------------------------------------------------------------------
# t2:
#   quality:
#     enabled: false               # must remain false in M6
#     normalizer:
#       stopwords: builtin         # or path: "examples/quality/stopwords.txt"
#       stemmer: none              # or "porter-lite"
#       min_token_len: 2
#     aliasing:
#       enabled: false
#       map_path: examples/quality/aliases.yaml
#       max_expansions_per_token: 2
#     lexical:
#       enabled: true
#       bm25: { k1: 1.2, b: 0.75, doclen_floor: 10 }
#     fusion:
#       enabled: true
#       alpha_semantic: 0.70
#       score_norm: zscore         # or "minmax"
#     mmr:
#       enabled: true
#       lambda_relevance: 0.75
#       diversity_by_owner: true
#       diversity_by_token: true
#       k_final: 64
#     cache:
#       salt: ""                   # optional; noop in M6
